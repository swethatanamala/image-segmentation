{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1cd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model import UNet\n",
    "from dataset import CarvanaDataset\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import transforms as tsfms\n",
    "import segmentation_models_pytorch as smp\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5666f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoint_overfit.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ = UNet(3, 2)\n",
    "# model_.load_state_dict(checkpoint['model_state_dict'])\n",
    "model1 = smp.Unet(\n",
    "    encoder_name='resnet34',  # Choose the encoder backbone, e.g., 'resnet18', 'resnet34', 'resnet50'\n",
    "    encoder_weights='imagenet',  # Use ImageNet pretraining weights\n",
    "    in_channels=3,  # Number of input channels (e.g., 3 for RGB images)\n",
    "    classes=2  # Number of output classes (e.g., 2 for binary segmentation)\n",
    ")\n",
    "model1.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d969f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {\n",
    "    \"train\": tsfms.Compose([\n",
    "        tsfms.RandomRotate(60),\n",
    "        tsfms.RandomSizedCrop(512, frac_range=[0.08, 1]),\n",
    "        tsfms.RandomHorizontalFlip(),\n",
    "        #tsfms.RandomIntensityJitter(0.1, 0.1),\n",
    "        tsfms.Clip(0, 255, 0, 1),\n",
    "        tsfms.ToTensor(),\n",
    "    ]),\n",
    "    \"val\": tsfms.Compose([\n",
    "        tsfms.Resize((512, 512)),\n",
    "        tsfms.Clip(0, 255, 0, 1),\n",
    "        tsfms.ToTensor()\n",
    "    ])\n",
    "}\n",
    "data_folder = \"/cache/fast_data_nas8/swetha\"\n",
    "train_dataset = CarvanaDataset(data_folder, data_limit=10, transforms=transforms)\n",
    "val_dataset = CarvanaDataset(data_folder, mode='val', data_limit=10, transforms=transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)  # Create your train data loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=True)  # Create your validation data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41fd87cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c91c4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_01_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_02_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_03_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_04_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_05_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_06_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_07_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_08_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_09_mask.gif',\n",
       " '/cache/fast_data_nas8/swetha/train_masks/00087a6bd4dc_10_mask.gif']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ab3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "plt.figure()\n",
    "plt.imshow(np.transpose(train_dataset[i]['image'].numpy(), (1, 2, 0)))\n",
    "plt.figure()\n",
    "plt.imshow(train_dataset[i]['target'].numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75543872",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = train_dataset[0]\n",
    "plt.figure()\n",
    "plt.imshow(mask, cmap='gray')\n",
    "img_numpy = img.numpy()\n",
    "img_numpy = np.transpose(img_numpy, (1, 2, 0))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a52c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img, mask in val_loader:\n",
    "    predictions = model1(img)\n",
    "    plt.figure()\n",
    "    plt.imshow(np.transpose(img[0].numpy(), (1, 2, 0)))\n",
    "    predictions_mask = torch.argmax(predictions, dim=1)\n",
    "    mask_numpy = np.int64(mask)\n",
    "    predictions_mask = np.int64(predictions_mask)\n",
    "    plt.figure()\n",
    "    plt.imshow(predictions_mask[0])\n",
    "    plt.figure()\n",
    "    plt.imshow(mask[0])\n",
    "    mask_numpy = mask.numpy()\n",
    "    print(mask_numpy.shape)\n",
    "    print(predictions_mask.shape)\n",
    "    dice = np.sum(predictions_mask[mask_numpy==1])*2.0 / (np.sum(predictions_mask) + np.sum(mask_numpy))\n",
    "    print(dice)\n",
    "    dice = metrics.dice_score(predictions, mask)\n",
    "    print(dice)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ba461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03fd07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
